"""Multi-run visualization utilities for quality test results.

Generates charts showing averaged metrics with error bars across multiple runs.
"""

from datetime import datetime
from pathlib import Path
from typing import Optional

import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import numpy as np

from tests.quality.models import MultiRunTestSuite
from tests.quality.aggregator import MultiRunAggregator
from src.lib.logging import get_logger

logger = get_logger(__name__)


def generate_multi_run_visualization(
    multi_run_suite: MultiRunTestSuite, output_file: Optional[str] = None
) -> str:
    """Generate visualization chart from multi-run test suite results.

    Creates a grouped bar chart showing averaged metrics per model with:
    - Average bars for score %, time, cost, characters
    - Error bars showing standard deviation
    - Individual data points overlaid on bars

    Args:
        multi_run_suite: Multi-run test suite results
        output_file: Optional file path to write chart to

    Returns:
        Path to generated PNG file
    """
    # Generate timestamp for filename
    dt = datetime.fromisoformat(multi_run_suite.last_run_timestamp)
    timestamp_str = dt.strftime("%Y-%m-%d_%H-%M-%S")

    if output_file is None:
        output_dir = Path("tests/quality/results")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"quality_test_{timestamp_str}_chart_multirun_{multi_run_suite.run_count}x.png"
    else:
        output_file = Path(output_file)

    # Create aggregator
    aggregator = MultiRunAggregator(multi_run_suite.run_suites)

    # Get models
    models = aggregator.models
    if not models:
        logger.warning("No models found in multi-run test suite")
        return str(output_file)

    # Collect averaged metrics and std devs
    avg_earned_pcts = []
    avg_llm_error_pcts = []
    avg_times = []
    avg_costs = []
    avg_chars = []

    std_earned_pcts = []
    std_llm_error_pcts = []
    std_times = []
    std_costs = []
    std_chars = []

    # Raw values for individual data points
    raw_earned_pcts_by_model = []
    raw_llm_error_pcts_by_model = []
    raw_times_by_model = []
    raw_costs_by_model = []
    raw_chars_by_model = []

    for model in models:
        avgs = aggregator.get_model_averages(model)
        stds = aggregator.get_model_std_devs(model)

        avg_earned_pcts.append(avgs['score_pct'])
        avg_llm_error_pcts.append(avgs['llm_error_pct'])
        avg_times.append(avgs['time'])
        avg_costs.append(avgs['cost'])
        avg_chars.append(avgs['chars'])

        std_earned_pcts.append(stds['score_pct'])
        std_llm_error_pcts.append(stds['llm_error_pct'])
        std_times.append(stds['time'])
        std_costs.append(stds['cost'])
        std_chars.append(stds['chars'])

        # Get raw values for scatter plot
        raw_earned_pcts_by_model.append(aggregator.get_model_raw_values(model, 'score_pct'))
        raw_llm_error_pcts_by_model.append(aggregator.get_model_raw_values(model, 'llm_error_pct'))
        raw_times_by_model.append(aggregator.get_model_raw_values(model, 'time'))
        raw_costs_by_model.append(aggregator.get_model_raw_values(model, 'cost'))
        raw_chars_by_model.append(aggregator.get_model_raw_values(model, 'chars'))

    # Create figure with space for queries at bottom
    fig, ax1 = plt.subplots(figsize=(14, 8))

    # Set up x-axis
    x = np.arange(len(models))
    width = 0.2  # Width of bars (adjusted for 4 bars)

    # Bar positions
    pos1 = x - 1.5 * width
    pos2 = x - 0.5 * width
    pos3 = x + 0.5 * width
    pos4 = x + 1.5 * width

    # Colors
    color_earned = '#2ecc71'  # Green for earned points
    color_llm_error = '#95a5a6'  # Grey for LLM errors
    color_time = '#3498db'  # Blue
    color_cost = '#e74c3c'  # Red
    color_chars = '#8B4513'  # Brown

    # Plot score % on left axis - use stacked bars with error bars
    # Bottom layer: earned score
    ax1.bar(pos1, avg_earned_pcts, width, label='Score % (earned)',
            color=color_earned, alpha=0.8, yerr=std_earned_pcts,
            capsize=3, error_kw={'elinewidth': 1, 'alpha': 0.7})

    # Top layer: LLM error (stacked on earned)
    ax1.bar(pos1, avg_llm_error_pcts, width, bottom=avg_earned_pcts,
            label='LLM Error %', color=color_llm_error, alpha=0.8,
            yerr=std_llm_error_pcts, capsize=3,
            error_kw={'elinewidth': 1, 'alpha': 0.7})

    # Overlay individual data points for score %
    for i, model in enumerate(models):
        # Earned points
        raw_vals = raw_earned_pcts_by_model[i]
        if raw_vals:
            x_positions = np.full(len(raw_vals), pos1[i])
            ax1.scatter(x_positions, raw_vals, color=color_earned, s=20,
                       alpha=0.6, zorder=10, edgecolors='black', linewidths=0.5)

        # LLM error points (stacked on earned)
        raw_llm_vals = raw_llm_error_pcts_by_model[i]
        if raw_llm_vals and raw_vals:
            # Stack on top of earned
            stacked_vals = [e + l for e, l in zip(raw_vals, raw_llm_vals)]
            x_positions = np.full(len(stacked_vals), pos1[i])
            ax1.scatter(x_positions, stacked_vals, color=color_llm_error, s=20,
                       alpha=0.6, zorder=10, edgecolors='black', linewidths=0.5)

    ax1.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Score %', fontsize=12, fontweight='bold', color=color_earned)
    ax1.tick_params(axis='y', labelcolor=color_earned)
    ax1.set_ylim(0, 100)
    ax1.set_xticks(x)
    ax1.set_xticklabels(models, rotation=45, ha='right')

    # Create second y-axis for time
    ax2 = ax1.twinx()
    ax2.bar(pos2, avg_times, width, label='Time (s)', color=color_time,
            alpha=0.8, yerr=std_times, capsize=3,
            error_kw={'elinewidth': 1, 'alpha': 0.7})

    # Overlay individual data points for time
    for i, model in enumerate(models):
        raw_vals = raw_times_by_model[i]
        if raw_vals:
            x_positions = np.full(len(raw_vals), pos2[i])
            ax2.scatter(x_positions, raw_vals, color=color_time, s=20,
                       alpha=0.6, zorder=10, edgecolors='black', linewidths=0.5)

    ax2.set_ylabel('Time (seconds)', fontsize=12, fontweight='bold', color=color_time)
    ax2.tick_params(axis='y', labelcolor=color_time)
    ax2.set_ylim(bottom=0)

    # Create third y-axis for cost
    ax3 = ax1.twinx()
    # Offset the third axis
    ax3.spines['right'].set_position(('outward', 60))
    ax3.bar(pos3, avg_costs, width, label='Cost (USD)', color=color_cost,
            alpha=0.8, yerr=std_costs, capsize=3,
            error_kw={'elinewidth': 1, 'alpha': 0.7})

    # Overlay individual data points for cost
    for i, model in enumerate(models):
        raw_vals = raw_costs_by_model[i]
        if raw_vals:
            x_positions = np.full(len(raw_vals), pos3[i])
            ax3.scatter(x_positions, raw_vals, color=color_cost, s=20,
                       alpha=0.6, zorder=10, edgecolors='black', linewidths=0.5)

    ax3.set_ylabel('Cost (USD)', fontsize=12, fontweight='bold', color=color_cost)
    ax3.tick_params(axis='y', labelcolor=color_cost)
    ax3.set_ylim(bottom=0)

    # Create fourth y-axis for characters
    ax4 = ax1.twinx()
    # Offset the fourth axis
    ax4.spines['right'].set_position(('outward', 120))
    ax4.bar(pos4, avg_chars, width, label='Characters', color=color_chars,
            alpha=0.8, yerr=std_chars, capsize=3,
            error_kw={'elinewidth': 1, 'alpha': 0.7})

    # Overlay individual data points for characters
    for i, model in enumerate(models):
        raw_vals = raw_chars_by_model[i]
        if raw_vals:
            x_positions = np.full(len(raw_vals), pos4[i])
            ax4.scatter(x_positions, raw_vals, color=color_chars, s=20,
                       alpha=0.6, zorder=10, edgecolors='black', linewidths=0.5)

    ax4.set_ylabel('Response Characters', fontsize=12, fontweight='bold', color=color_chars)
    ax4.tick_params(axis='y', labelcolor=color_chars)
    ax4.set_ylim(bottom=0)

    # Title
    plt.title(f'Model Performance Comparison (N={multi_run_suite.run_count} runs, averaged)',
              fontsize=14, fontweight='bold', pad=20)

    # Add legend
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    lines3, labels3 = ax3.get_legend_handles_labels()
    lines4, labels4 = ax4.get_legend_handles_labels()
    ax1.legend(lines1 + lines2 + lines3 + lines4,
               labels1 + labels2 + labels3 + labels4,
               loc='upper left', fontsize=9)

    # Grid for readability
    ax1.grid(axis='y', alpha=0.3, linestyle='--')

    # Add test queries at the bottom with reduced spacing
    # Get unique queries from first run
    test_queries = set()
    if multi_run_suite.run_suites:
        for result in multi_run_suite.run_suites[0].test_results:
            clean_query = result.query.replace('\\"', '"').replace("\\'", "'")
            test_queries.add(clean_query)

    sorted_queries = sorted(test_queries)
    query_lines = ["Test Queries:"]
    for q in sorted_queries:
        query_lines.append(f"â€¢ {q}")

    # Join with minimal spacing
    query_text = "\n".join(query_lines)
    plt.figtext(0.1, 0.02, query_text, fontsize=9, va='top',
                linespacing=1)  # Reduced line spacing

    # Note about error bars
    # note_text = f"Error bars show standard deviation across {multi_run_suite.run_count} runs. Dots show individual run values."
    # plt.figtext(0.1, 0.01, note_text, fontsize=8, va='top',
    #             style='italic', color='#666666')

    # Adjust layout to make room for queries
    plt.subplots_adjust(bottom=0.25)

    # Save figure
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()

    logger.info(f"Multi-run visualization saved to {output_file}")
    return str(output_file)
